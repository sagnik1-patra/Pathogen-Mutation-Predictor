{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96be2a0d-b581-4390-84fa-2d0469ed7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading mutation data...\n",
      "[INFO] Combined mutation shape: (8873, 7)\n",
      "[INFO] Metadata shape: (3786, 31)\n",
      "[INFO] Metadata columns: ['sample_id', 'year', 'country', 'continent', 'beta.lactamase', 'azithromycin', 'ciprofloxacin', 'ceftriaxone', 'cefixime', 'tetracycline'] ...\n",
      "[INFO] Using 'sample_id' as merge key (converted to string).\n",
      "[INFO] Final merged shape: (17, 37)\n",
      "[WARN] Auto-selected potential target column: country\n",
      "[INFO] Target column detected: country\n",
      "[INFO] Feature matrix shape: (17, 23)\n",
      "[INFO] Train/Test split: (12, 23), (5, 23)\n",
      "[INFO] Training RandomForest...\n",
      "[RESULT] RandomForest Accuracy: 1.0000\n",
      "[INFO] Training Deep Learning Model...\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4694 - accuracy: 1.0000 - val_loss: 0.5716 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4200 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3963 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3262 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3092 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2662 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.2580 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1882 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1682 - accuracy: 1.0000 - val_loss: 0.1886 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1566 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1201 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0989 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "[RESULT] Deep Learning Accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All results saved in: C:\\Users\\NXTWAVE\\Downloads\\Pathogen Mutation Predictor\n",
      " ‚îú‚îÄ‚îÄ biomind_model.pkl\n",
      " ‚îú‚îÄ‚îÄ biomind_dl.h5\n",
      " ‚îú‚îÄ‚îÄ biomind_metadata.yaml\n",
      " ‚îú‚îÄ‚îÄ resistance_prediction.json\n",
      " ‚îú‚îÄ‚îÄ accuracy_graph.png\n",
      " ‚îú‚îÄ‚îÄ mutation_heatmap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NXTWAVE\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üß¨ Paths\n",
    "# ---------------------------------------------------------------------\n",
    "BASE_DIR = r\"C:\\Users\\NXTWAVE\\Downloads\\Pathogen Mutation Predictor\"\n",
    "DATA_PATHS = [\n",
    "    os.path.join(BASE_DIR, \"archive\", \"azm_sr_gwas_filtered_unitigs.Rtab\"),\n",
    "    os.path.join(BASE_DIR, \"archive\", \"cfx_sr_gwas_filtered_unitigs.Rtab\"),\n",
    "    os.path.join(BASE_DIR, \"archive\", \"cip_sr_gwas_filtered_unitigs.Rtab\"),\n",
    "]\n",
    "META_PATH = os.path.join(BASE_DIR, \"archive\", \"metadata.csv\")\n",
    "OUT_DIR = BASE_DIR\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üß© 1Ô∏è‚É£ Load Mutation Data\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"[INFO] Loading mutation data...\")\n",
    "\n",
    "dfs = []\n",
    "for path in DATA_PATHS:\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Rtab tables have features as rows and samples as columns -> transpose\n",
    "    if df.shape[1] > 5:\n",
    "        df = df.T\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df[1:]\n",
    "    df.index.name = \"SampleID\"\n",
    "    df.reset_index(inplace=True)\n",
    "    dfs.append(df)\n",
    "\n",
    "merged = dfs[0]\n",
    "for i in range(1, len(dfs)):\n",
    "    merged = pd.merge(merged, dfs[i], on=\"SampleID\", how=\"outer\")\n",
    "\n",
    "# Force SampleID to string\n",
    "merged[\"SampleID\"] = merged[\"SampleID\"].astype(str)\n",
    "\n",
    "print(f\"[INFO] Combined mutation shape: {merged.shape}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üß´ 2Ô∏è‚É£ Load Metadata\n",
    "# ---------------------------------------------------------------------\n",
    "meta = pd.read_csv(META_PATH)\n",
    "meta.columns = (\n",
    "    meta.columns.str.strip()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(\"-\", \"_\")\n",
    "    .str.lower()\n",
    ")\n",
    "print(f\"[INFO] Metadata shape: {meta.shape}\")\n",
    "print(f\"[INFO] Metadata columns: {list(meta.columns)[:10]} ...\")\n",
    "\n",
    "# Find sample key (case-insensitive)\n",
    "possible_ids = [\"sampleid\", \"sample_id\", \"id\", \"isolate\", \"run\", \"strain\"]\n",
    "meta_key = None\n",
    "for key in possible_ids:\n",
    "    if key in meta.columns:\n",
    "        meta_key = key\n",
    "        break\n",
    "\n",
    "if meta_key is None:\n",
    "    raise KeyError(\n",
    "        f\"‚ùå No ID column found. Available: {list(meta.columns)}. \"\n",
    "        \"Expected something like sample_id or isolate.\"\n",
    "    )\n",
    "\n",
    "meta.rename(columns={meta_key: \"SampleID\"}, inplace=True)\n",
    "meta[\"SampleID\"] = meta[\"SampleID\"].astype(str)\n",
    "print(f\"[INFO] Using '{meta_key}' as merge key (converted to string).\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üß¨ 3Ô∏è‚É£ Merge\n",
    "# ---------------------------------------------------------------------\n",
    "data = pd.merge(meta, merged, on=\"SampleID\", how=\"inner\")\n",
    "print(f\"[INFO] Final merged shape: {data.shape}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üßÆ 4Ô∏è‚É£ Target Column Detection\n",
    "# ---------------------------------------------------------------------\n",
    "target_candidates = [\n",
    "    c for c in data.columns if any(x in c.lower() for x in [\"resistance\", \"phenotype\", \"label\", \"response\"])\n",
    "]\n",
    "if not target_candidates:\n",
    "    # fallback: maybe \"azithromycin\", \"ciprofloxacin\" etc are resistance status\n",
    "    possible_targets = [c for c in data.columns if data[c].nunique() <= 3]\n",
    "    if possible_targets:\n",
    "        label_col = possible_targets[0]\n",
    "        print(f\"[WARN] Auto-selected potential target column: {label_col}\")\n",
    "    else:\n",
    "        raise ValueError(f\"‚ùå No suitable resistance column found. Columns: {list(data.columns)[:15]}\")\n",
    "else:\n",
    "    label_col = target_candidates[0]\n",
    "\n",
    "print(f\"[INFO] Target column detected: {label_col}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üî¨ 5Ô∏è‚É£ Preprocess\n",
    "# ---------------------------------------------------------------------\n",
    "y = (\n",
    "    data[label_col]\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .map({\"resistant\": 1, \"r\": 1, \"susceptible\": 0, \"s\": 0})\n",
    ")\n",
    "# if still NaN, fill binary numeric or 0/1 fallback\n",
    "if y.isna().all():\n",
    "    y = pd.to_numeric(data[label_col], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "X = (\n",
    "    data.drop(columns=[label_col, \"SampleID\"], errors=\"ignore\")\n",
    "    .select_dtypes(include=[np.number, np.float64, np.int64])\n",
    "    .fillna(0)\n",
    ")\n",
    "print(f\"[INFO] Feature matrix shape: {X.shape}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"[INFO] Train/Test split: {X_train.shape}, {X_test.shape}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üå≤ 6Ô∏è‚É£ RandomForest Model\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"[INFO] Training RandomForest...\")\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "print(f\"[RESULT] RandomForest Accuracy: {rf_acc:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# ü§ñ 7Ô∏è‚É£ Deep Learning Model\n",
    "# ---------------------------------------------------------------------\n",
    "print(\"[INFO] Training Deep Learning Model...\")\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[es],\n",
    "    verbose=1\n",
    ")\n",
    "dl_acc = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "print(f\"[RESULT] Deep Learning Accuracy: {dl_acc:.4f}\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üìä 8Ô∏è‚É£ Plots\n",
    "# ---------------------------------------------------------------------\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"mutation_heatmap.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar([\"RandomForest\", \"DeepLearning\"], [rf_acc, dl_acc], color=['skyblue','orange'])\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"accuracy_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# üíæ 9Ô∏è‚É£ Save Artifacts\n",
    "# ---------------------------------------------------------------------\n",
    "joblib.dump(rf, os.path.join(OUT_DIR, \"biomind_model.pkl\"))\n",
    "model.save(os.path.join(OUT_DIR, \"biomind_dl.h5\"))\n",
    "\n",
    "metadata = {\n",
    "    \"project\": \"BioMind - Pathogen Mutation Predictor\",\n",
    "    \"models\": {\"RandomForest\": float(rf_acc), \"DeepLearning\": float(dl_acc)},\n",
    "    \"merge_key\": meta_key,\n",
    "    \"target_column\": label_col,\n",
    "    \"train_shape\": X_train.shape,\n",
    "    \"test_shape\": X_test.shape,\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, \"biomind_metadata.yaml\"), \"w\") as f:\n",
    "    yaml.dump(metadata, f)\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"TrueLabel\": y_test.values,\n",
    "    \"Pred_RF\": rf_pred,\n",
    "    \"Pred_DL\": y_pred.flatten()\n",
    "})\n",
    "pred_df.to_json(os.path.join(OUT_DIR, \"resistance_prediction.json\"), orient=\"records\", indent=4)\n",
    "\n",
    "print(\"\\n‚úÖ All results saved in:\", OUT_DIR)\n",
    "for f in [\"biomind_model.pkl\", \"biomind_dl.h5\", \"biomind_metadata.yaml\", \"resistance_prediction.json\", \"accuracy_graph.png\", \"mutation_heatmap.png\"]:\n",
    "    print(\" ‚îú‚îÄ‚îÄ\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ae94e2-f92c-442c-9ba0-9f1692fb5e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
